{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSR\n",
    "* Get generated code into a file\n",
    "* Attempt to compile the file when formatted correctly\n",
    "* 1 for successful compilation, 0 for unsuccessful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CodeBLEU\n",
    "* Different considerations rather than simple n-gram matching (BLEU)\n",
    "    * Weighted N-Gram Matching\n",
    "    * Syntactic AST Match\n",
    "    * Semantic Data-flow Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 61.08 ; Acc: 50.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'CodeXGLUE/Code-Code/code-to-code-trans/evaluator/evaluator.py', '-ref', 'CodeXGLUE/Code-Code/code-to-code-trans/evaluator/references.txt', '-pre', 'CodeXGLUE/Code-Code/code-to-code-trans/evaluator/predictions.txt'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "subprocess.run([\"python\", \"CodeXGLUE/Code-Code/code-to-code-trans/evaluator/evaluator.py\", \"-ref\", \"CodeXGLUE/Code-Code/code-to-code-trans/evaluator/references.txt\", \"-pre\", \"CodeXGLUE/Code-Code/code-to-code-trans/evaluator/predictions.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM (Exact Match)\n",
    "* Purely Matching whether all characters match\n",
    "* Key things to think about:\n",
    "    * Removing white space\n",
    "    * Cleaning output for direct comparison\n",
    "    * Simple string comparison works perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exact_match(prediction, reference):\n",
    "    prediction = prediction.strip()\n",
    "    reference = reference.strip()\n",
    "\n",
    "    # OTHER CLEANING GOES HERE FOR EACH OUTPUT\n",
    "\n",
    "    return prediction == reference\n",
    "\n",
    "output = \"def main():\\n\\tprint('Hello World')\"\n",
    "target = \"def main():\\n\\tprint('Hello World')\"\n",
    "\n",
    "exact_match(output, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acc@10 (Any top 10 generations exactly match)\n",
    "* Model needs to generation 10 responses for each example\n",
    "* Iterate through all 10 example for comparison\n",
    "* Use same logic as EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_at_10(predictions, reference):\n",
    "    for prediction in predictions:\n",
    "        prediction = prediction.strip()\n",
    "        print(prediction)\n",
    "\n",
    "    reference = reference.strip()\n",
    "\n",
    "    # OTHER CLEANING GOES HERE FOR EACH OUTPUT\n",
    "\n",
    "    for prediction in predictions:\n",
    "        if prediction==reference:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "predictions = [\"def hello_world:\\n\\tprint('Hello, World!')\", \"def hello_world:\\n\\tprint('Hello, World)\", \"def hello_world:\\n\\tprint('Hello, World!\\\")\", \"def hello_world:\\n\\tprint('Hello, World!)\", \"def hello_world:\\n\\tprint('Hello, World!)\", \"def hello_world:\\n\\tprint(\\\"Hello, World!\\\")\", \"def print_hello_world:\\n\\tprint('Hello, World!)\", \"def helloworld:\\n\\tprint('Hello, World!)\", \"def hello_world:\\n\\tprint('Hello, World)\", \"def hello_world:\\n\\tprint('Hello World!)\"] \n",
    "reference = \"def hello_world:\\n\\tprint('Hello, World!')\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Similarity (Levenshtein Edit Distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Coverage\n",
    "* Lines Executed / Total Executable Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branch Coverage\n",
    "* Branches Executed / Total Executable Lines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UnitTestGeneration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
