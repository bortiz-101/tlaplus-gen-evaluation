{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Experiment Structure\n",
    "* Using different models\n",
    "* Run on same sample for all models\n",
    "* Evaluate outputs after\n",
    "\n",
    "#### Pseudocode\n",
    "for every model{\n",
    "    generate 10 responses for all samples(for Acc@10)\n",
    "    store samples properly    \n",
    "}\n",
    "\n",
    "for each model's generated samples{\n",
    "    calculate metrics (CSR, CodeBLEU, EM, Acc@10, Edit Similarity, Line Coverage, Branch Coverage)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mujtaba/DATA/nick/miniconda3/envs/UnitTestGeneration/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import multiprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "#from accelerate import PartialState\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    logging,\n",
    "    set_seed,\n",
    "    pipeline,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/starcoder2-3b\")\n",
    "\n",
    "# config\n",
    "# load model and dataset\n",
    "#token = os.environ.get(\"HF_TOKEN\", None)\n",
    "# print out selected device\n",
    "#print(PartialState().process_index)\n",
    "#Check for GPU availability\n",
    "# print(torch.cuda.is_available())\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"GPU\")\n",
    "#     with torch.device(\"cuda:2\"):\n",
    "#         model = AutoModelForCausalLM.from_pretrained(\n",
    "#             \"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\",\n",
    "#             quantization_config=bnb_config,\n",
    "#             attention_dropout=0.1,\n",
    "#             device_map=None, #Prevents auto device mapping - not really\n",
    "#             trust_remote_code=True,\n",
    "#         )\n",
    "#         model.to(\"cuda:2\")\n",
    "# else:\n",
    "#     #Handle no GPU availiability\n",
    "#     print(\"No GPU\")\n",
    "#     with torch.device(\"cpu\"):\n",
    "#         model = AutoModelForCausalLM.from_pretrained(\n",
    "#             \"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\",\n",
    "#             quantization_config=bnb_config,\n",
    "#             attention_dropout=0.1,\n",
    "#             device_map=None, #Prevents auto device mapping - not really\n",
    "#             trust_remote_code=True,\n",
    "#         )\n",
    "#         model.to(\"cpu\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"bigcode/starcoder2-3b\",\n",
    "    #quantization_config=bnb_config,\n",
    "    #attention_dropout=0.1,\n",
    "    device_map=None, #Prevents auto device mapping - not really\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    print(\"Using DataParallel for multiple GPUs\")\n",
    "#    model = torch.nn.DataParallel(model)\n",
    "\n",
    "#model.to(device)\n",
    "# Freeze all except embeddings and first layer\n",
    "#for name, param in model.named_parameters():\n",
    "#    if \"model.embed_tokens\" not in name and \"model.layers.0\" not in name:\n",
    "#        param.requires_grad = False\n",
    "#    else:\n",
    "#        param.requries_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(args.dataset_name)\n",
    "#     print(args.subset)\n",
    "#     print(args.split)\n",
    "#     print(token)\n",
    "#     print(args.num_proc if args.num_proc else multiprocessing.cpu_count())\n",
    "    \n",
    "#     '''Original file from hugging face hub\n",
    "#     data = load_dataset(\n",
    "#         args.dataset_name,\n",
    "#         data_files=args.subset,\n",
    "#         split=args.split,\n",
    "#         token=token,\n",
    "#         num_proc=args.num_proc if args.num_proc else multiprocessing.cpu_count(),\n",
    "#     )'''\n",
    "\n",
    "#     data = load_dataset(\n",
    "#         'parquet', \n",
    "#         data_files=args.subset, \n",
    "#         split=args.split,\n",
    "#         num_proc=args.num_proc if args.num_proc else multiprocessing.cpu_count(),\n",
    "#     )\n",
    "\n",
    "#     print('Dataset type: ', type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods2Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breaking\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy\n",
    "\n",
    "# Define the base directories\n",
    "base_dirs = ['train', 'eval', 'test']\n",
    "\n",
    "for i in range(len(base_dirs)):\n",
    "    base_dirs[i] = '../../../data/methods2test_data/' + base_dirs[i]\n",
    "# List to collect all data (rows)\n",
    "data = []\n",
    "\n",
    "total_exmaples = 0\n",
    "\n",
    "is_broken = False\n",
    "base_dir = '../../../data/methods2test_data/train'\n",
    "# Iterate over all subdirectories (examples) in the base directory\n",
    "for example_dir in os.listdir(base_dir):\n",
    "    example_path = os.path.join(base_dir, example_dir)\n",
    "    \n",
    "    # Ensure we're dealing with directories (i.e., each example is its own directory)\n",
    "    if os.path.isdir(example_path):\n",
    "        # Use glob to get all JSON files in the example directory\n",
    "        json_files = glob(os.path.join(example_path, '*.json'))\n",
    "        \n",
    "        # Iterate over the JSON files\n",
    "        for json_file in json_files:\n",
    "            # Read the JSON data\n",
    "            with open(json_file, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            # Add the JSON data to the data list (can modify if additional info is needed)\n",
    "            data.append(json_data)\n",
    "            total_exmaples+=1\n",
    "            if(total_exmaples>=100):\n",
    "                print(\"breaking\")\n",
    "                is_broken = True\n",
    "                break\n",
    "    if(is_broken):\n",
    "        break\n",
    "# Convert the collected data into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optional: Inspect the first few rows\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a Java method that sums two numbers and returns the result\"\n",
    "\n",
    "response = text_generator(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a Java method that sums two numbers and returns the result\n",
      "\n",
      "Write a Java method that sums two numbers and returns the resultgn\u0005\n"
     ]
    }
   ],
   "source": [
    "print(prompt + \"\\n\")\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_methods = df['focal_method']\n",
    "code_bodies = pd.DataFrame({'code': focal_methods.apply(lambda x: x['body'])})\n",
    "\n",
    "test_cases = df[\"test_case\"]\n",
    "test_code_bodies = pd.DataFrame({'tests': test_cases.apply(lambda x: x['body'])})\n",
    "\n",
    "code_test_df = pd.concat([code_bodies, test_code_bodies], axis=1)\n",
    "\n",
    "code_test_df['prompted_code'] = \"Here is a method implementation in Java:\\n\\n\" + code_test_df['code'] + \"\\n\\nWrite a full test class with test cases to validate the method defined above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(code_test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "ds = load_dataset(\"THUDM/humaneval-x\", \"java\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_block_comments(java_code):\n",
    "    pattern = re.compile(r'/\\*.*?\\*/\\s*\\n?', re.DOTALL)  # Finds block and newline character after\n",
    "    \n",
    "    # Substitute block comments (and following newline) with empty string\n",
    "    cleaned_code = re.sub(pattern, '', java_code)\n",
    "    \n",
    "    return cleaned_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"//Source method\\n\" + remove_block_comments(ds['test'][45]['prompt']) + ds['test'][45]['canonical_solution'] + \"\\n\\n//Unit Tests with Three Cases\\n\" + ds['test'][45]['test']\n",
    "prompt = prompt + \"\\n\\n\\n//Source method\\n\" + remove_block_comments(ds['test'][23]['prompt']) + ds['test'][23]['canonical_solution'] + \"\\n\\n//Unit Tests with Three Cases\\n\" + \"public class Main {\\n    public static void main(String[] args) {\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding prompts with different starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def match_main_class(java_code):\n",
    "    \"\"\"\n",
    "    Matches Java code that starts exactly with:\n",
    "    public class Main {\n",
    "        public static void main(String[] args) {\n",
    "    \n",
    "    Args:\n",
    "        java_code (str): The Java source code as a string.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the code matches the exact structure, False otherwise.\n",
    "    \"\"\"\n",
    "    # Regex pattern for exact match\n",
    "    pattern = re.compile(\n",
    "        r'^public class Main \\{\\n\\s+public static void main\\(String\\[\\] args\\) \\{', \n",
    "        re.MULTILINE\n",
    "    )\n",
    "    \n",
    "    # Check if pattern matches the start of the string\n",
    "    return bool(pattern.match(java_code))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163]\n",
      "Not consistent examples: [38, 50, 162]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "consistent_start = []\n",
    "inconsistent_start = []\n",
    "for i, ex in enumerate(ds['test']):\n",
    "    test_code = ex['test']\n",
    "\n",
    "    match = match_main_class(test_code)\n",
    "\n",
    "    if match:\n",
    "        consistent_start.append(i)\n",
    "    else:\n",
    "        inconsistent_start.append(i)\n",
    "\n",
    "print(consistent_start)\n",
    "print(f\"Not consistent examples: {inconsistent_start}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Experiment (Input and Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The model 'CodeGenForCausalLM' is not supported for text2text-generation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# def generate_responses_from_df(\n",
    "#     df: pd.DataFrame,\n",
    "#     text_column: str,\n",
    "#     text_generator,         \n",
    "#     max_length: int = 100,\n",
    "#     output_csv: str = \"generated_responses.csv\",\n",
    "#     timing_file: str = \"timing.txt\",\n",
    "#     batch_size: int = 8,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Iterates through all rows in `df`, uses a text-generation pipeline to\n",
    "#     generate responses for each row's text, and stores the results in a CSV.\n",
    "#     Also logs total time to a text file.\n",
    "#     \"\"\"\n",
    "#     dataset = Dataset.from_pandas(df)\n",
    "#     # 1) Start timing\n",
    "#     print(\"Starting Experiment\")\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # 2) Generate responses\n",
    "\n",
    "#     def generate_text(batch, text_generator=None):\n",
    "#         prompts = batch[\"prompted_code\"]\n",
    "#         outputs = text_generator(batch[\"prompted_code\"])\n",
    "#         # If the pipeline returns a list of dict, handle that\n",
    "#         generated_texts = [o[\"generated_text\"] for o in outputs]\n",
    "#         return {\"generated_text\": generated_texts}\n",
    "\n",
    "#     generated_dataset = dataset.map(generate_text, \n",
    "#                                     fn_kwargs= {\"text_generator\": text_generator}, \n",
    "#                                     desc=\"Processing dataset\", \n",
    "#                                     batched=True, \n",
    "#                                     batch_size=batch_size,\n",
    "#                                     #num_proc=4,\n",
    "#     )\n",
    "\n",
    "#     # 3) End timing\n",
    "#     end_time = time.time()\n",
    "#     total_time = end_time - start_time\n",
    "\n",
    "#     # 4) Store and save results\n",
    "#     df = generated_dataset.to_pandas()\n",
    "#     df.to_csv(output_csv, index=False)\n",
    "\n",
    "#     with open(timing_file, \"a\") as f:\n",
    "#         f.write(f\"Total generation time (seconds) for batch size {batch_size}: {total_time}\\n\")\n",
    "\n",
    "#     print(f\"Saved responses to {output_csv}. Total time: {total_time:.2f} seconds\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Use the pipeline you created earlier\n",
    "\n",
    "#     for num in [1,2,4,8,16,32,64]:\n",
    "#         generate_responses_from_df(\n",
    "#             df=code_test_df,\n",
    "#             text_column=\"prompted_code\",\n",
    "#             text_generator=text_generator,  # pipeline we created\n",
    "#             max_length=1000,  \n",
    "#             output_csv=\"my_generated_responses.csv\",\n",
    "#             timing_file=\"my_timing_log.txt\",\n",
    "#             batch_size=num\n",
    "#         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I m a king.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"Say something back to me that makes logical sense.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_responses_from_df\u001b[39m(\n\u001b[1;32m      6\u001b[0m     df: pd\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[1;32m      7\u001b[0m     text_column: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     timing_file: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtiming.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m ):\n",
      "File \u001b[0;32m/media/mujtaba/DATA/nick/miniconda3/envs/UnitTestGeneration/lib/python3.9/site-packages/pandas/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     ArrowDtype,\n\u001b[1;32m     52\u001b[0m     Int8Dtype,\n\u001b[1;32m     53\u001b[0m     Int16Dtype,\n\u001b[1;32m     54\u001b[0m     Int32Dtype,\n\u001b[1;32m     55\u001b[0m     Int64Dtype,\n\u001b[1;32m     56\u001b[0m     UInt8Dtype,\n\u001b[1;32m     57\u001b[0m     UInt16Dtype,\n\u001b[1;32m     58\u001b[0m     UInt32Dtype,\n\u001b[1;32m     59\u001b[0m     UInt64Dtype,\n\u001b[1;32m     60\u001b[0m     Float32Dtype,\n\u001b[1;32m     61\u001b[0m     Float64Dtype,\n\u001b[1;32m     62\u001b[0m     CategoricalDtype,\n\u001b[1;32m     63\u001b[0m     PeriodDtype,\n\u001b[1;32m     64\u001b[0m     IntervalDtype,\n\u001b[1;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     66\u001b[0m     StringDtype,\n\u001b[1;32m     67\u001b[0m     BooleanDtype,\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     NA,\n\u001b[1;32m     70\u001b[0m     isna,\n\u001b[1;32m     71\u001b[0m     isnull,\n\u001b[1;32m     72\u001b[0m     notna,\n\u001b[1;32m     73\u001b[0m     notnull,\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     Index,\n\u001b[1;32m     76\u001b[0m     CategoricalIndex,\n\u001b[1;32m     77\u001b[0m     RangeIndex,\n\u001b[1;32m     78\u001b[0m     MultiIndex,\n\u001b[1;32m     79\u001b[0m     IntervalIndex,\n\u001b[1;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     81\u001b[0m     DatetimeIndex,\n\u001b[1;32m     82\u001b[0m     PeriodIndex,\n\u001b[1;32m     83\u001b[0m     IndexSlice,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     NaT,\n\u001b[1;32m     86\u001b[0m     Period,\n\u001b[1;32m     87\u001b[0m     period_range,\n\u001b[1;32m     88\u001b[0m     Timedelta,\n\u001b[1;32m     89\u001b[0m     timedelta_range,\n\u001b[1;32m     90\u001b[0m     Timestamp,\n\u001b[1;32m     91\u001b[0m     date_range,\n\u001b[1;32m     92\u001b[0m     bdate_range,\n\u001b[1;32m     93\u001b[0m     Interval,\n\u001b[1;32m     94\u001b[0m     interval_range,\n\u001b[1;32m     95\u001b[0m     DateOffset,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     to_numeric,\n\u001b[1;32m     98\u001b[0m     to_datetime,\n\u001b[1;32m     99\u001b[0m     to_timedelta,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     Flags,\n\u001b[1;32m    102\u001b[0m     Grouper,\n\u001b[1;32m    103\u001b[0m     factorize,\n\u001b[1;32m    104\u001b[0m     unique,\n\u001b[1;32m    105\u001b[0m     value_counts,\n\u001b[1;32m    106\u001b[0m     NamedAgg,\n\u001b[1;32m    107\u001b[0m     array,\n\u001b[1;32m    108\u001b[0m     Categorical,\n\u001b[1;32m    109\u001b[0m     set_eng_float_format,\n\u001b[1;32m    110\u001b[0m     Series,\n\u001b[1;32m    111\u001b[0m     DataFrame,\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m/media/mujtaba/DATA/nick/miniconda3/envs/UnitTestGeneration/lib/python3.9/site-packages/pandas/core/api.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     NaT,\n\u001b[1;32m      3\u001b[0m     Period,\n\u001b[1;32m      4\u001b[0m     Timedelta,\n\u001b[1;32m      5\u001b[0m     Timestamp,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     ArrowDtype,\n\u001b[1;32m     11\u001b[0m     CategoricalDtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     PeriodDtype,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m/media/mujtaba/DATA/nick/miniconda3/envs/UnitTestGeneration/lib/python3.9/site-packages/pandas/_libs/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     NaT,\n\u001b[1;32m     21\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     iNaT,\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:398\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "def generate_responses_from_df(\n",
    "    df: pd.DataFrame,\n",
    "    text_column: str,\n",
    "    model_name: str,\n",
    "    device: int = -1,\n",
    "    max_length: int = 100,\n",
    "    output_csv: str = \"generated_responses.csv\",\n",
    "    timing_file: str = \"timing.txt\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1. Iterates through all rows in `df`.\n",
    "    2. Uses a text-generation pipeline to generate responses for each row's text.\n",
    "    3. Stores the responses and saves them to `output_csv`.\n",
    "    4. Logs total time taken to `timing_file`.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Initialize text-generation pipeline\n",
    "    text_generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_name,\n",
    "        device=device  # -1 = CPU; 0 or other ints = specific GPU\n",
    "    )\n",
    "\n",
    "    # 2) Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 3) Iterate through the DataFrame, generate responses\n",
    "    responses = []\n",
    "    for i, row in df.iterrows():\n",
    "        prompt_text = row[text_column]\n",
    "\n",
    "        # Generate text (You can tune these kwargs—max_length, etc.)\n",
    "        output = text_generator(prompt_text, max_length=max_length, num_return_sequences=1)\n",
    "        \n",
    "        # output is a list of dicts, e.g. [{'generated_text': \"...\"}]\n",
    "        generated_text = output[0][\"generated_text\"]\n",
    "        responses.append(generated_text)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    # 4) Add responses to DataFrame and save\n",
    "    df[\"response\"] = responses\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    # Save timing info\n",
    "    with open(timing_file, \"w\") as f:\n",
    "        f.write(f\"Total generation time (seconds): {total_time}\\n\")\n",
    "\n",
    "    print(f\"Saved responses to {output_csv}.\")\n",
    "    print(f\"Total time: {total_time:.2f} seconds\")\n",
    "\n",
    "# ------------------------\n",
    "# Example usage\n",
    "# ------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Suppose your CSV has a column \"prompt\" with text to be processed\n",
    "    df_input = pd.DataFrame({\n",
    "        \"prompt\": [\n",
    "            \"Explain why the sky is blue.\",\n",
    "            \"Write a short poem about cats.\",\n",
    "            \"Summarize the benefits of exercise.\"\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    generate_responses_from_df(\n",
    "        df=df_input,\n",
    "        text_column=\"prompt\",\n",
    "        model_name=\"gpt2\",      # or any other HF model, e.g. \"gpt2-medium\", \"gpt-neo-125M\", etc.\n",
    "        device=-1,              # use CPU; set to 0 for first GPU, 1 for second GPU, etc.\n",
    "        max_length=50,\n",
    "        output_csv=\"my_generated_responses.csv\",\n",
    "        timing_file=\"my_timing_log.txt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Training (In case of potential use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "os.makedirs(\"../models/experiment_testing\", exist_ok=True)\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# setup the trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=8,\n",
    "        warmup_steps=100,\n",
    "        max_steps=10000,\n",
    "        #max_seq_length=512,\n",
    "        learning_rate=2e-4,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        weight_decay=0.01,\n",
    "        bf16=False,################Originally True\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=10,\n",
    "        output_dir=\"../models/experiment_testing\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        seed=0,\n",
    "        run_name=f\"train-deepseekcoder-v2-methods2test\",\n",
    "        report_to=\"wandb\",\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    #dataset_text_field=\"prompted_code\",\n",
    ")\n",
    "# launch\n",
    "print(\"Training...\")\n",
    "trainer.train()\n",
    "print(\"Saving the last checkpoint of the model\")\n",
    "model.save_pretrained(os.path.join(args.output_dir, args.model_id + \"_\" + args.subset + \"_final_checkpoint/\"))\n",
    "'''if args.push_to_hub:\n",
    "    trainer.push_to_hub(\"Upload model\", token=os.getenv(\"HUGGINGFACE_TOKEN\")'''\n",
    "print(\"Training Done! 💥\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UnitTestGeneration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
