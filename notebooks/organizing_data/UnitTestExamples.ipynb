{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for Prompts Asking for Unit Tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "code_table = pq.read_table(\"train-00000-of-00001-d9b93805488c263e.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121959"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instruction', 'input', 'output', 'prompt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_table.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.StringScalar: 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDevelop a function that will add two strings\\n\\n### Input:\\nstr1 = \"Hello \"\\nstr2 = \"world\"\\n\\n### Response:\\ndef add_strings(str1, str2):\\n    \"\"\"This function takes two strings and returns the sum of them.\"\"\"\\n    return str1 + str2\\n\\nstr1 = \"Hello \"\\nstr2 = \"world\"\\nsum_of_strings = add_strings(str1, str2)'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_table[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples with 'unit test': 22\n",
      "Number of rows in unit_test_examples: 22\n",
      "Examples saved to unit_test_examples.parquet\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Define the regex pattern to match \"unit test\" (case-insensitive)\n",
    "pattern = r\"\\bunit test\\b\"\n",
    "\n",
    "# Initialize counters and result storage\n",
    "sum = 0\n",
    "matching_examples = []\n",
    "unit_test_examples = None\n",
    "\n",
    "# Iterate over the instructions column\n",
    "for i, instruction in enumerate(code_table.column('instruction')):\n",
    "    example = instruction.as_py()\n",
    "    # Perform case-insensitive search\n",
    "    match = re.search(pattern, example, re.IGNORECASE)\n",
    "    if match:\n",
    "        sum += 1\n",
    "        new_batch = code_table.slice(i, 1)\n",
    "        matching_examples.append(new_batch)\n",
    "\n",
    "# Print the total number of matches\n",
    "print(\"Number of examples with 'unit test':\", sum)\n",
    "\n",
    "# Concatenate all matching examples into a single table\n",
    "unit_test_examples = pa.concat_tables(matching_examples)\n",
    "print(\"Number of rows in unit_test_examples:\", len(unit_test_examples))\n",
    "\n",
    "# Save the matching examples to a Parquet file\n",
    "pq.write_table(unit_test_examples, 'unit_test_examples.parquet')\n",
    "print(\"Examples saved to unit_test_examples.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_test_samples = pq.read_table(\"unit_test_examples.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.StringScalar: 'Create a unit test to check if two numbers are equal to each other.'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_test_examples[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instruction: string\n",
       "input: string\n",
       "output: string\n",
       "prompt: string\n",
       "-- schema metadata --\n",
       "huggingface: '{\"info\": {\"features\": {\"instruction\": {\"dtype\": \"string\", \"' + 165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_test_examples.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved as unit_test_examples.json\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "\n",
    "# Load the Parquet file\n",
    "parquet_file = 'unit_test_examples.parquet'  # Replace with your Parquet file name\n",
    "table = pq.read_table(parquet_file)\n",
    "\n",
    "# Convert the Parquet data to a list of dictionaries\n",
    "data = table.to_pydict()  # Convert table to a dictionary of lists\n",
    "\n",
    "# Reformat into the desired JSON structure\n",
    "reformatted_data = [\n",
    "    {\n",
    "        \"instruction\": data[\"instruction\"][i],\n",
    "        \"input\": data[\"input\"][i],\n",
    "        \"output\": data[\"output\"][i],\n",
    "        \"prompt\": data[\"prompt\"][i],\n",
    "    }\n",
    "    for i in range(len(data[\"instruction\"]))\n",
    "]\n",
    "\n",
    "# Save to a JSON file\n",
    "json_file = 'unit_test_examples.json'\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(reformatted_data, f, indent=4)\n",
    "\n",
    "print(f\"JSON file saved as {json_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for Outputs with Unit Tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples with 'assert': 155\n",
      "Number of rows in unit_test_assert_examples: 155\n",
      "Examples saved to unit_test_assert_examples.parquet\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Define the regex pattern to match \"unit test\" (case-insensitive)\n",
    "pattern = r\"\\bassert\\b\"\n",
    "\n",
    "# Initialize counters and result storage\n",
    "sum = 0\n",
    "matching_examples = []\n",
    "unit_test_assert_examples = None\n",
    "\n",
    "# Iterate over the instructions column\n",
    "for i, instruction in enumerate(code_table.column('output')):\n",
    "    example = instruction.as_py()\n",
    "    # Perform case-insensitive search\n",
    "    match = re.search(pattern, example, re.IGNORECASE)\n",
    "    if match:\n",
    "        sum += 1\n",
    "        new_batch = code_table.slice(i, 1)\n",
    "        matching_examples.append(new_batch)\n",
    "\n",
    "# Print the total number of matches\n",
    "print(\"Number of examples with 'assert':\", sum)\n",
    "\n",
    "# Concatenate all matching examples into a single table\n",
    "unit_test_assert_examples = pa.concat_tables(matching_examples)\n",
    "print(\"Number of rows in unit_test_assert_examples:\", len(unit_test_assert_examples))\n",
    "\n",
    "# Save the matching examples to a Parquet file\n",
    "pq.write_table(unit_test_assert_examples, 'unit_test_assert_examples.parquet')\n",
    "print(\"Examples saved to unit_test_assert_examples.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved as unit_test_assert_examples.json\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "\n",
    "# Load the Parquet file\n",
    "parquet_file = 'unit_test_assert_examples.parquet'  # Replace with your Parquet file name\n",
    "table = pq.read_table(parquet_file)\n",
    "\n",
    "# Convert the Parquet data to a list of dictionaries\n",
    "data = table.to_pydict()  # Convert table to a dictionary of lists\n",
    "\n",
    "# Reformat into the desired JSON structure\n",
    "reformatted_data = [\n",
    "    {\n",
    "        \"instruction\": data[\"instruction\"][i],\n",
    "        \"input\": data[\"input\"][i],\n",
    "        \"output\": data[\"output\"][i],\n",
    "        \"prompt\": data[\"prompt\"][i],\n",
    "    }\n",
    "    for i in range(len(data[\"instruction\"]))\n",
    "]\n",
    "\n",
    "# Save to a JSON file\n",
    "json_file = 'unit_test_assert_examples.json'\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(reformatted_data, f, indent=4)\n",
    "\n",
    "print(f\"JSON file saved as {json_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
